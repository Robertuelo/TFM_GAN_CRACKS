{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#torch cuda\nimport torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"68eb8eae-4bb5-48e4-b4ac-98149e9e1a7d","_cell_guid":"b15b930a-d383-4164-97ae-38f4fe59fe57","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:43:46.135859Z","iopub.execute_input":"2023-06-21T14:43:46.136488Z","iopub.status.idle":"2023-06-21T14:43:50.895440Z","shell.execute_reply.started":"2023-06-21T14:43:46.136453Z","shell.execute_reply":"2023-06-21T14:43:50.894382Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.utils.data import DataLoader","metadata":{"_uuid":"70d2c9b4-5e3d-4e20-a887-bbc452a8dc3a","_cell_guid":"0565fc75-2d82-4ce6-b2c9-7919ad10ec5a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:43:50.900322Z","iopub.execute_input":"2023-06-21T14:43:50.902989Z","iopub.status.idle":"2023-06-21T14:43:50.910562Z","shell.execute_reply.started":"2023-06-21T14:43:50.902958Z","shell.execute_reply":"2023-06-21T14:43:50.908450Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# cargar dataset \n\nimport os\nimport numpy as np\nfrom PIL import Image\n\ndef load_dataset(folder_path):\n\n    # Obtener la lista de archivos en la carpeta\n    file_list = os.listdir(folder_path)\n\n    # Filtrar los archivos por extensión (por ejemplo, solo archivos JPG)\n    jpg_files = [file_name for file_name in file_list if file_name.endswith(\".jpg\")]\n\n    # Crear una lista vacía para almacenar las imágenes\n    images = []\n\n    # Recorrer la lista de archivos JPG\n    for file_name in jpg_files:\n        # Combinar la ruta de la carpeta con el nombre del archivo\n        file_path = os.path.join(folder_path, file_name)\n\n        # Abrir la imagen usando PIL\n        image = Image.open(file_path)\n\n        # Convertir la imagen a un arreglo numpy\n        image_np = np.array(image)\n\n        # Agregar la imagen al listado de imágenes\n        images.append(image_np)\n\n    # Convertir la lista de imágenes a un arreglo numpy\n    dataset = np.array(images, dtype=object)\n\n    return dataset\n\nx_train_path = \"/kaggle/input/crack50020220509t090436z001/CRACK500/traincrop/traincrop\"\ny_train_path = \"/kaggle/input/crack50020220509t090436z001/CRACK500/valcrop/valcrop\"\n\nx_train = load_dataset(x_train_path)\ny_train = load_dataset(y_train_path)\n# Verificar la forma del arreglo x_train\nprint(x_train.shape)\nprint(y_train.shape)","metadata":{"_uuid":"b0d22482-2832-4733-9b69-2159639b4136","_cell_guid":"d78653bd-98c6-402e-a0e3-b6bb7be5be75","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:43:54.426209Z","iopub.execute_input":"2023-06-21T14:43:54.426555Z","iopub.status.idle":"2023-06-21T14:44:13.073136Z","shell.execute_reply.started":"2023-06-21T14:43:54.426527Z","shell.execute_reply":"2023-06-21T14:44:13.071102Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(1896,)\n(348,)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cambiar las imagenes de tamño\n\nimport cv2\nimport numpy as np\n\n# Especifica el tamaño deseado para las imágenes\ntarget_size = (64, 64)\n\ndef img_resize(target_size, dataset):\n    # Crea una lista para almacenar las imágenes redimensionadas\n    resized_images = []\n\n    # Itera sobre las imágenes en x_train y redimensiona cada una\n    for img in dataset:\n        resized_img = cv2.resize(img, target_size)\n        resized_images.append(resized_img)\n\n    # Convierte la lista de imágenes redimensionadas en un arreglo numpy\n    dataset_resized = np.array(resized_images)\n    \n    return dataset_resized\n\nx_train_resized = img_resize(target_size, x_train)\ny_train_resized = img_resize(target_size, y_train)\nprint(x_train_resized.shape)\nprint(y_train_resized.shape)","metadata":{"_uuid":"30dcc7bc-7393-44de-b66d-e4af7d50aa0d","_cell_guid":"538ca26b-1dcd-4c6d-ab29-1dff524105a0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:44:31.644971Z","iopub.execute_input":"2023-06-21T14:44:31.645358Z","iopub.status.idle":"2023-06-21T14:44:31.979589Z","shell.execute_reply.started":"2023-06-21T14:44:31.645318Z","shell.execute_reply":"2023-06-21T14:44:31.978430Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(1896, 64, 64, 3)\n(348, 64, 64, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Rotar las imagenes para aumentar el dataset\n\nimport numpy as np\nfrom scipy.ndimage import rotate\n\ndef rotate_images(images, angles=[90, 180, 270]):\n    # Crear una lista vacía para almacenar las imágenes rotadas\n    rotated_images = []\n    \n    # Iterar sobre todas las imágenes y ángulos de rotación\n    for image in images:\n        for angle in angles:\n            rotated_image = rotate(image, angle, reshape=False)\n            rotated_images.append(rotated_image)\n    \n    # Convertir la lista de imágenes rotadas en un array numpy\n    rotated_images = np.array(rotated_images)\n    \n    return rotated_images\n\nx_train_resized=rotate_images(x_train_resized)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:44:46.361999Z","iopub.execute_input":"2023-06-21T14:44:46.362358Z","iopub.status.idle":"2023-06-21T14:45:02.394466Z","shell.execute_reply.started":"2023-06-21T14:44:46.362330Z","shell.execute_reply":"2023-06-21T14:45:02.393377Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Vale necesito pasar las imagenes a un  y normalizarlas\n\nX_train_tensor = torch.from_numpy(x_train_resized).float()\nX_train_tensor = X_train_tensor / 255  # Esto lo normalizará al rango de 0 a 1","metadata":{"_uuid":"d7ab2945-6b7c-456d-8f31-3901d33c125c","_cell_guid":"97004297-3de9-47b7-9291-2cbc7fa01814","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:45:08.362945Z","iopub.execute_input":"2023-06-21T14:45:08.363319Z","iopub.status.idle":"2023-06-21T14:45:08.799443Z","shell.execute_reply.started":"2023-06-21T14:45:08.363292Z","shell.execute_reply":"2023-06-21T14:45:08.798428Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Arquitectura de la red\n#GENERADOR\n\nclass Generator(nn.Module):\n    def __init__(self, z_dim=100, channels_img=3, features_g=64):\n        super(Generator, self).__init__()\n        self.gen = nn.Sequential(\n            # Entrada: Tensor de ruido (N, z_dim, 1, 1)\n            self._block(z_dim, features_g * 16, 4, 1, 0),  # img: 4x4\n            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n            self._block(features_g * 2, features_g, 4, 2, 1),  # img: 64x64\n            nn.ConvTranspose2d(\n                features_g, channels_img, kernel_size=4, stride=2, padding=1\n            ),  # img: 128x128\n            nn.Tanh(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        return self.gen(x)\n\n","metadata":{"_uuid":"bd0336f9-ba15-4d15-a220-08ec720a6a92","_cell_guid":"cf7d5a7a-9de5-40b7-8a6c-e8ec67f20fde","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:45:23.041393Z","iopub.execute_input":"2023-06-21T14:45:23.041745Z","iopub.status.idle":"2023-06-21T14:45:23.051301Z","shell.execute_reply.started":"2023-06-21T14:45:23.041717Z","shell.execute_reply":"2023-06-21T14:45:23.050108Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Arquitectura de la red \n#Discriminador \n\nclass Discriminator(nn.Module):\n    def __init__(self, channels_img=3, features_d=64):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # Entrada: N x channels_img x 128 x 128\n            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),  # img: 64x64\n            nn.LeakyReLU(0.2),\n            self._block(features_d, features_d * 2, 4, 2, 1),  # img: 32x32\n            self._block(features_d * 2, features_d * 4, 4, 2, 1),  # img: 16x16\n            self._block(features_d * 4, features_d * 8, 4, 2, 1),  # img: 8x8\n            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),  # img: 4x4\n            nn.Sigmoid(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n            ),\n            nn.InstanceNorm2d(out_channels, affine=True),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.disc(x)\n\n","metadata":{"_uuid":"89d2249f-e58f-4da8-9f04-b81da9b464fb","_cell_guid":"fbb15a74-e780-4eee-a161-eee0f74325ff","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:47:08.960513Z","iopub.execute_input":"2023-06-21T14:47:08.960911Z","iopub.status.idle":"2023-06-21T14:47:08.971292Z","shell.execute_reply.started":"2023-06-21T14:47:08.960879Z","shell.execute_reply":"2023-06-21T14:47:08.970165Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Entrenamiento normal sin entrenar varias veces el generador\n\"\"\"\ndef train(dataloader, generator, discriminator, optim_g, optim_d, loss_fn, device, z_dim):\n    for real in dataloader:\n        real = real.to(device)\n        real = real.permute(0,3,1,2)\n        noise = torch.randn((real.size(0), z_dim, 1, 1)).to(device)\n        fake = generator(noise)\n\n        ### Actualiza el discriminador ###\n        disc_real = discriminator(real).view(-1)\n        loss_disc_real = loss_fn(disc_real, torch.ones_like(disc_real))\n        disc_fake = discriminator(fake.detach()).view(-1)\n        loss_disc_fake = loss_fn(disc_fake, torch.zeros_like(disc_fake))\n        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n        discriminator.zero_grad()\n        loss_disc.backward()\n        optim_d.step()\n\n        ### Actualiza el generador ###\n        output = discriminator(fake).view(-1)\n        loss_gen = loss_fn(output, torch.ones_like(output))\n        generator.zero_grad()\n        loss_gen.backward()\n        optim_g.step()\n        print(f\"Epoch [{epoch}/{num_epochs}] Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\")\n        return generator,discriminator\n\n\"\"\"\na=5\n\n\n","metadata":{"_uuid":"0c9c93e0-da40-438a-a803-69178a2ffa26","_cell_guid":"c2668994-608c-4d26-b8fc-7146cd90e1a7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-21T14:57:11.904493Z","iopub.execute_input":"2023-06-21T14:57:11.905006Z","iopub.status.idle":"2023-06-21T14:57:11.911810Z","shell.execute_reply.started":"2023-06-21T14:57:11.904966Z","shell.execute_reply":"2023-06-21T14:57:11.910902Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, generator, discriminator, opt_gen, opt_disc, criterion, device, z_dim, n_gen_updates=2):\n    generator.train()\n    discriminator.train()\n\n    for epoch in range(num_epochs):\n        for batch_idx, real in enumerate(dataloader):\n            real = real.to(device)\n            noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n\n            # Entrenar Discriminador: max log(D(x)) + log(1 - D(G(z)))\n            discriminator.zero_grad()\n            real=real.permute(0,3,1,2)\n            real_output = discriminator(real)\n            real_loss = criterion(real_output, torch.ones_like(real_output))\n            fake = generator(noise)\n            fake_output = discriminator(fake.detach())\n            fake_loss = criterion(fake_output, torch.zeros_like(fake_output))\n            lossD = real_loss + fake_loss\n            lossD.backward()\n            opt_disc.step()\n\n            # Entrenar Generador: max log(D(G(z)))\n            for _ in range(n_gen_updates):\n                generator.zero_grad()\n                output = discriminator(fake)\n                lossG = criterion(output, torch.ones_like(output))\n                if _ == n_gen_updates - 1:\n                    lossG.backward()  # en la última iteración no necesitamos mantener el grafo\n                else:\n                    lossG.backward(retain_graph=True)  # mantener el grafo para futuras iteraciones\n                opt_gen.step()\n\n        print(f\"Epoch [{epoch}/{num_epochs}] Loss D: {lossD.item()}, loss G: {lossG.item()}\")\n    return generator, discriminator\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:57:15.841957Z","iopub.execute_input":"2023-06-21T14:57:15.842331Z","iopub.status.idle":"2023-06-21T14:57:15.853309Z","shell.execute_reply.started":"2023-06-21T14:57:15.842302Z","shell.execute_reply":"2023-06-21T14:57:15.852242Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Hiperparametros\nz_dim = 100\nlr = 0.0002\nbatch_size = 32\nnum_epochs=250\n\n#Discriminador\ndiscriminator = Discriminator().to(device)\ngenerator = Generator(z_dim).to(device)\n\n#Optimizador\nopt_disc = torch.optim.Adam(discriminator.parameters(), lr=lr)\nopt_gen = torch.optim.Adam(generator.parameters(), lr=lr)\n\n#Criterio\ncriterion = nn.BCELoss()\n\n#Ruido\nfixed_noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n\n#Dataloader\ndataloader = DataLoader(X_train_tensor, batch_size=batch_size, shuffle=True)\n\n#Entrenamineto\ngenerator,discriminator = train(dataloader, generator, discriminator, opt_gen, opt_disc, criterion, device, z_dim, n_gen_updates=3)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:57:19.532708Z","iopub.execute_input":"2023-06-21T14:57:19.533426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mostrar resultados\n\nimport matplotlib.pyplot as plt\n\n# Fijar la semilla del generador de números aleatorios\ntorch.manual_seed(42)\n\n# Número de imágenes para generar\nnum_images = 10\n\n# Crear ruido aleatorio\nz = torch.randn(num_images, z_dim, 1, 1).to(device)\n\n# Poner el generador en modo evaluación y generar imágenes\ngenerator.eval()\nwith torch.no_grad():\n    fake_imgs = generator(z).detach().cpu()\n\n# Crear una figura para el grid de imágenes\nfig, axs = plt.subplots(2, 5, figsize=(15, 6))\n\n# Iterar sobre las imágenes generadas\nfor i in range(num_images):\n    fake_img = fake_imgs[i]\n\n    # Eliminar la primera dimensión y mover los canales de color al final\n    fake_img = fake_img.squeeze(0).permute(1, 2, 0)\n    fake_img = (fake_img + 1)*0.5  # Esto deshace la normalización típica de [-1, 1] usada en las imágenes de entrada a los GANs\n\n    # Mostrar imagen en el grid\n    row = i // 5\n    col = i % 5\n    axs[row, col].imshow(fake_img)\n    axs[row, col].axis('off')  # Quita los ejes para una visualización más clara\n\nplt.tight_layout()\nplt.show()\n","metadata":{"_uuid":"953bd2bf-1b7f-4a27-80a1-c090b4fe252c","_cell_guid":"151ce32a-cbb2-421f-99b7-782ac043794f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"6466c4be-9719-4a25-9d59-6eddbe0e3e78","_cell_guid":"54165a8b-558f-4320-966d-b78bd456eeb4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}